<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Multi-Label Audio Tagging With Fastai2 Audio | Mike’s Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Multi-Label Audio Tagging With Fastai2 Audio" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition" />
<meta property="og:description" content="A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition" />
<link rel="canonical" href="https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html" />
<meta property="og:url" content="https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html" />
<meta property="og:site_name" content="Mike’s Blog" />
<meta property="og:image" content="https://mikful.github.io/mike-blog/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-16T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition","dateModified":"2020-04-16T00:00:00-05:00","datePublished":"2020-04-16T00:00:00-05:00","headline":"Multi-Label Audio Tagging With Fastai2 Audio","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html"},"image":"https://mikful.github.io/mike-blog/images/some_folder/your_image.png","url":"https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/mike-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mikful.github.io/mike-blog/feed.xml" title="Mike's Blog" /><link rel="shortcut icon" type="image/x-icon" href="/mike-blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Multi-Label Audio Tagging With Fastai2 Audio | Mike’s Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Multi-Label Audio Tagging With Fastai2 Audio" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition" />
<meta property="og:description" content="A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition" />
<link rel="canonical" href="https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html" />
<meta property="og:url" content="https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html" />
<meta property="og:site_name" content="Mike’s Blog" />
<meta property="og:image" content="https://mikful.github.io/mike-blog/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-16T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition","dateModified":"2020-04-16T00:00:00-05:00","datePublished":"2020-04-16T00:00:00-05:00","headline":"Multi-Label Audio Tagging With Fastai2 Audio","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html"},"image":"https://mikful.github.io/mike-blog/images/some_folder/your_image.png","url":"https://mikful.github.io/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://mikful.github.io/mike-blog/feed.xml" title="Mike's Blog" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/mike-blog/">Mike&#39;s Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/mike-blog/about/">About Me</a><a class="page-link" href="/mike-blog/search/">Search</a><a class="page-link" href="/mike-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Multi-Label Audio Tagging With Fastai2 Audio</h1><p class="page-description">A Udacity ML Engineer Nanodegree Capstone Projec: Using the in-development fastai2 audio library on the Kaggle Freesound 2019 Competition</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-16T00:00:00-05:00" itemprop="datePublished">
        Apr 16, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/mike-blog/categories/#audio">audio</a>
        &nbsp;
      
        <a class="category-tags-link" href="/mike-blog/categories/#deep learning">deep learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/mike-blog/categories/#SageMaker">SageMaker</a>
        &nbsp;
      
        <a class="category-tags-link" href="/mike-blog/categories/#GCP">GCP</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#-">  </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Machine-Listening">Machine Listening </a></li>
<li class="toc-entry toc-h2"><a href="#Freesound-2019-Kaggle-Competition">Freesound 2019 Kaggle Competition </a></li>
<li class="toc-entry toc-h2"><a href="#EDA---WIP">EDA - WIP </a></li>
<li class="toc-entry toc-h2"><a href="#Developing-the-Model---To-Do">Developing the Model - To Do </a></li>
<li class="toc-entry toc-h2"><a href="#Results---To-Do">Results - To Do </a></li>
<li class="toc-entry toc-h2"><a href="#Evaluation-of-Model---To-Do">Evaluation of Model - To Do </a></li>
<li class="toc-entry toc-h2"><a href="#What's-Next...">What&#39;s Next... </a></li>
<li class="toc-entry toc-h2"><a href="#Thanks">Thanks </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-16-Freesound-2019-Audio-Tagging-With-Fastai.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="-">
<a class="anchor" href="#-" aria-hidden="true"><span class="octicon octicon-link"></span></a> <a class="anchor-link" href="#-"> </a>
</h1>
<hr>
<p>Sections:</p>
<p>Remember to fully reference and give thanks to references</p>
<ul>
<li>Intro to Competition</li>
<li>Intro to Fastai2 Audio</li>
<li>Downloading the Data</li>
<li>EDA</li>
<li>Audio Data intro</li>
<li>Chosen Spectrogram settings and Augmentations</li>
<li>
<p>2-stage Training Method - 2-Stage Kfold, Model details, learning rates</p>
<ul>
<li>why good: </li>
<li>used 1/5 training time of high scorers (approximately)</li>
<li>No time-consuming pre-processing </li>
<li>multi-label accuracy within 98% in a few epochs on simple accuracy_multi metric</li>
</ul>
</li>
<li>Results  </li>
<li>What's next <ul>
<li>self supervised learning?</li>
<li>improving on model</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Machine-Listening">
<a class="anchor" href="#Machine-Listening" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Listening<a class="anchor-link" href="#Machine-Listening"> </a>
</h2>
<p>The sub-field of Machine Learning known as Machine Listening is a burgeoning area of research using signal processing for the automatic extraction of information from sound by a computational analysis of audio. There are many different areas of research within this field as demonstrated by the latest Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 Challenge, a machine learning challenge dedicated to the research and development of new methods and algorithms. These include:</p>
<ul>
<li>Acoustic Scene Classification</li>
<li>Sound Event Detection and Localization</li>
<li>Sound Event Detection and Separation in Domestic Environments</li>
<li>Urban Sound tagging</li>
<li>Automated Audio Captioning</li>
</ul>
<p>As an acoustic engineer, I am extremely intrigued by this new field. Recent developments in machine learning algorithms have allowed significant progress to be made within this area, with the potential applications of the technology being wide and varied and meaning the tools could prove to be extremely useful for the acoustic practitioner amongst many other uses.</p>
<p>The in-development user-contributed fast.ai2 Audio library <sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup> inspired me to undertake the development of a deep learning audio-tagging system for my Udacity Capstone project, as described in this blog post.</p>
<p></p>
<div class="footnotes"><p id="fn-1">1. <a href="https://github.com/rbracco/fastai2_audio">fast.ai 2 audio</a><a href="#fnref-1" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Freesound-2019-Kaggle-Competition">
<a class="anchor" href="#Freesound-2019-Kaggle-Competition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Freesound 2019 Kaggle Competition<a class="anchor-link" href="#Freesound-2019-Kaggle-Competition"> </a>
</h2>
<p><strong>Problem</strong></p>
<p>The Freesound Audio Tagging 2019 <sup id="fnref-2" class="footnote-ref"><a href="#fn-2">2</a></sup> Kaggle Competition provides the basis for my research project.</p>
<p>The challenge is to develop a system for the automatic classification of multi-labelled audio files within 80 categories, that could potentially be used for automatic audio/video file tagging and/or real-time sound event detection with noisy or untagged audio data. This has historically been investigated in a variety of ways:</p>
<ul>
<li>Conversion of audio to mel-spectrogram images fed into CNNs</li>
<li>End-to-End Deep learning</li>
<li>Custom architectures involving auto-encoders</li>
<li>Features representation transfer learning with custom architectures and Google's Audioset</li>
</ul>
<p><strong>Dataset</strong></p>
<p>In addition, the classification of weakly labelled data from large-scale crowdsourced datasets provides a further problem for investigation[^2]. The dataset comprises the following elements:</p>
<p>The dataset used in the challenge is called FSDKaggle2019[^1] and was collected by members of Freesound (a Creative Commons Licensed sound database from the Music Technology Group of Universitat Pempeu Fabra, Barcelona) and Google Research's Machine Perception Team[^2].</p>
<ul>
<li>Freesound Dataset (<a href="https://annotator.freesound.org/fsd/">FSD</a>): a dataset being collected at the <a href="https://www.upf.edu/web/mtg">MTG-UPF</a> based on <a href="https://freesound.org/">Freesound</a> content organized with the <a href="https://research.google.com/audioset////////ontology/index.html">AudioSet Ontology</a> and manually labelled by humans.</li>
<li>The soundtracks of a pool of Flickr videos taken from the <a href="http://code.flickr.net/2014/10/15/the-ins-and-outs-of-the-yahoo-flickr-100-million-creative-commons-dataset/">Yahoo Flickr Creative Commons 100M dataset (YFCC)</a> which are automatically labelled using metadata from the original Flickr clips. These items therefore have significantly more label noise than the Freesound Dataset items.</li>
</ul>
<p>The data comprises 80 categories labelled according to Google's Audioset Ontology [^3] with ground truth labels provided at the clip level. The clips range in duration between 0.3 to 30s in uncompressed PCM 16 bit, 44.1 kHz mono audio files.</p>
<p><strong>Metric</strong></p>
<p>The problem is clearly quantifiable in that a number of accuracy metrics could be used to quantify the accuracy of the model's predictions, however, the competition used label-weighted-label-ranked-precision (lwl-rap, or 'lol-rap') as the metric, as the advancement of audio multi-labelling has acheived &gt;95% accuracy with ease in recent years. This will be discussed in further detail below.</p>
<ul>
<li>Intro - from proposal<ul>
<li>Problem - tagging data using noisy datasets and small curated set</li>
</ul>
</li>
<li>Multi-label - lwl-wrap (more on that later)</li>
<li>Data sets - Curated and Noisy</li>
</ul>
<p></p>
<div class="footnotes"><p id="fn-2">2. <a href="https://www.kaggle.com/c/freesound-audio-tagging-2019/overview">Kaggle Freesound Audio Tagging 2019 Competition</a><a href="#fnref-2" class="footnote footnotes">↩</a></p></div>

<pre><code>* Difference between audio and other data*</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="EDA---WIP">
<a class="anchor" href="#EDA---WIP" aria-hidden="true"><span class="octicon octicon-link"></span></a>EDA - WIP<a class="anchor-link" href="#EDA---WIP"> </a>
</h2>
<p>The first stage of the process was to understand the dataset more fully. Fortunately, due to being a Kaggle Competition dataset it was well documented and clean in terms of organization.</p>
<p>Downloading the dataset was undertaken using guidance given within <a href="https://www.kaggle.com/c/deepfake-detection-challenge/discussion/129521">the following link</a> directly into the SageMaker/GCP Instance storage for easy access.</p>
<p>The files were then unzipped for the EDA. For further details, please see the <a href="https://github.com/mikful/udacity-mlend-capstone/blob/master/nbs_final/eda.ipynb">notebook directly</a>.</p>
<p><strong>Pandas and Pandas Profiling</strong></p>
<p>In order to undertake the analysis of the data, Pandas and Pandas Profiling were used.</p>
<p><a href="https://github.com/pandas-profiling/pandas-profiling">Pandas Profiling</a> is an extremely useful add-on package to Pandas, which creates HTMl profile reports directly from Pandas DataFrames quickly and easily.</p>
<p>Using these two packages the following was found:</p>
<p><strong>Curated Data</strong></p>
<p><strong>Noisy Data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Developing-the-Model---To-Do">
<a class="anchor" href="#Developing-the-Model---To-Do" aria-hidden="true"><span class="octicon octicon-link"></span></a>Developing the Model - To Do<a class="anchor-link" href="#Developing-the-Model---To-Do"> </a>
</h2>
<p>Although the course was taught using SageMaker, for the training an AI Notebook instance on GCP was used, as the author had free credits available and the GPU training times were likely to be significantly longer than possible with the remaining SageMaker credit from the course.</p>
<ul>
<li>Audio Data intro</li>
<li>Chosen Spectrogram settings and Augmentations</li>
<li>
<p>2-stage Training Method - 2-Stage Kfold, Model details, learning rates</p>
<ul>
<li>why good: </li>
<li>used 1/5 training time of high scorers (approximately)</li>
<li>No time-consuming pre-processing </li>
<li>multi-label accuracy within 98% in a few epochs on simple accuracy_multi metric</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Results---To-Do">
<a class="anchor" href="#Results---To-Do" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results - To Do<a class="anchor-link" href="#Results---To-Do"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-of-Model---To-Do">
<a class="anchor" href="#Evaluation-of-Model---To-Do" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluation of Model - To Do<a class="anchor-link" href="#Evaluation-of-Model---To-Do"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What's-Next...">
<a class="anchor" href="#What's-Next..." aria-hidden="true"><span class="octicon octicon-link"></span></a>What's Next...<a class="anchor-link" href="#What's-Next..."> </a>
</h2>
<ul>
<li>Deploy a model using SageMaker / GCP for inference of user-uploaded audio.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Thanks">
<a class="anchor" href="#Thanks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Thanks<a class="anchor-link" href="#Thanks"> </a>
</h2>
<p>Thanks to fastai and the fastai2-audio and fastpages communities whose amazing efforts and incredible generosity have made this learning journey possible.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="mikful/mike-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/mike-blog/audio/deep%20learning/sagemaker/gcp/2020/04/16/Freesound-2019-Audio-Tagging-With-Fastai.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/mike-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/mike-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/mike-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog about my journey into Machine Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/mikful" title="mikful"><svg class="svg-icon grey"><use xlink:href="/mike-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/mikful" title="mikful"><svg class="svg-icon grey"><use xlink:href="/mike-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
